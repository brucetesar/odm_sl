Todo List for odm_sl

UF_LEARNING.RB
Both uf_learning.rb and fewest_set_features.rb have methods named
test_unset_feature().

FewestSetFeatures#test_unset_feature(): set the target feature to match
surface, all other unset features to mismatch surface. See if it is consistent.

OTLearn.test_unset_feature(): find the number of consistent values of the
unset feature; if there is only one consistent value, set the feature. Accounts
for conflicting feature values within a set of words.

Most of the methods in uf_learning.rb are only called internally,
i.e., elsewhere in uf_learning.rb.
Called Outside
.set_uf_values() called by contrast_pair_learning, single_form_learning

.conflicting_output_values?() called by contrast_pair.rb

.find_unset_features_in_words() called by fewest_set_features.rb ONLY

.find_unset_features() called by contrast_pair.rb

.find_morphemes_in_words() called by contrast_pair.rb

OTHER
OTLearn::match_input_to_uf!(Word) (defined in data_manip.rb) should be
eliminated. Taking an output and parsing it with the grammar will give a
*new* word with the input matched to the lexicon.

Add some basic field value validation to OTGeneric::Erc_conversion.

Implement a ranking information (erc list) only linguistic system and
grammar class. Use it to set up basic bin scripts for experimenting with
different ranking biases.

Create some more substantive specs for Mrcd.

Either find some reasonable way to unit-test LoserSelector_by_ranking,
or delete the specs for it.

Investigate the effects of using, in GrammarTest, LoserSelectorExhaustive
instead of LoserSelector_by_ranking(FaithLow). That would mean that a word
only succeeds evaluation if its max mismatch form is the sole optimum for
every support-consistent ranking.
